{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "import pytz\n",
    "print(pd.__version__)\n",
    "utc = pytz.utc\n",
    "\n",
    "datDir = \"./withings/raw_sleep-monitor_sleep-state.csv\"\n",
    "\n",
    "\n",
    "\n",
    "with open (datDir, \"r\") as myfile:\n",
    "    dataSTRs=myfile.readlines()\n",
    "dataSTRs = dataSTRs[1:]#remove the title bar\n",
    "\n",
    "outputFileName = \"withingsBedSleepStages.parquet.gzip\"\n",
    "outputTimezone = -7\n",
    "\n",
    "dataFileColumns = [\"timestamp\", \"stage\", \"endTimestamp\"]\n",
    "\n",
    "\n",
    "#get list of files in current directroy\n",
    "files = [f for f in os.listdir(\"./\") if os.path.isfile(f)]\n",
    "\n",
    "print(files)\n",
    "print(outputFileName in files)\n",
    "#if the output file isn't already made, make it\n",
    "if not (outputFileName in files):\n",
    "    print(\"making new df\")\n",
    "    emptydf = pd.DataFrame(columns = dataFileColumns)\n",
    "    emptydf.set_index('timestamp')\n",
    "    print(emptydf)\n",
    "        \n",
    "    #save as a parquet file\n",
    "    emptydf.to_parquet(outputFileName, compression='gzip') \n",
    "\n",
    "\n",
    "df = pd.read_parquet(outputFileName)\n",
    "\n",
    "print(df.head(100))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.2.4\n",
      "['importHaloSleep.ipynb', 'importwithings.ipynb']\n",
      "False\n",
      "making new df\n",
      "Empty DataFrame\n",
      "Columns: [timestamp, stage, endTimestamp]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [timestamp, stage, endTimestamp]\n",
      "Index: []\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#ok I'm just going to assume that the gps corrdinates are necessary metadata to get the local time offset\n",
    "#i'm just going to manually get all of the values from the data exports in UTC time and then calculate the local offset later\n",
    "\n",
    "# timezone tests\n",
    "testdt = datetime.datetime(2002, 10, 27, 6, 0, 0)\n",
    "print(testdt)\n",
    "print(testdt.tzinfo)\n",
    "testdt = utc.localize(testdt)\n",
    "print(testdt)\n",
    "print(testdt.tzinfo)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2002-10-27 06:00:00\n",
      "None\n",
      "2002-10-27 06:00:00+00:00\n",
      "UTC\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#readlines\n",
    "#the problem where if there is only one element in the list there are no quotes used so the formatting is slightly diffrent \n",
    "\n",
    "for r in dataSTRs:\n",
    "    datList = r.split('[')\n",
    "    toadd = []\n",
    "\n",
    "    time = pd.to_datetime(datList[0].split(\"+\")[0], format='%Y-%m-%dT%H:%M:%S') \n",
    "    tzoffset = datetime.timedelta(hours=(-1 * int(datList[0].split(\"+\")[1][1])))#it's stored in french time so the offset should always be +\n",
    "    startTime = utc.localize(time + tzoffset)\n",
    "    stageStartTime = startTime\n",
    "    toadd.append(stageStartTime)\n",
    "    #print(stageStartTime)\n",
    "    #print(tzoffset)\n",
    "\n",
    "    #first i want to check if the datList[2]s length is == 2 and if so parse it diffrently, write the toadd and continue\n",
    "    if len(datList[2].strip()) == 2:\n",
    "        toadd.append(int(datList[2][0]))\n",
    "        toadd.append(stageStartTime + datetime.timedelta(minutes=1))\n",
    "        df.loc[stageStartTime] = toadd\n",
    "    else:\n",
    "        stagelist = datList[2].strip()[:-2].split(',') #remove newline, clsose bracket and close quote, and split on commas\n",
    "        #print(stagelist)\n",
    "        \n",
    "        #get the first stage in the row and add it to tooadd and set it to lastStage\n",
    "        toadd.append(int(stagelist[0]))\n",
    "        for i in range(1,len(stagelist)):\n",
    "            if stagelist[i] != stagelist[i-1]:\n",
    "                #save the current time as the end of the last stage\n",
    "                toadd.append(startTime + datetime.timedelta(minutes=i))\n",
    "                #add to the df\n",
    "                df.loc[stageStartTime] = toadd\n",
    "                #reset toadd\n",
    "                toadd = []\n",
    "                #set the current time to the start of the next one\n",
    "                stageStartTime = startTime + datetime.timedelta(minutes=i)\n",
    "                toadd.append(stageStartTime)\n",
    "                #set the lable of the next stage to the value of the current index\n",
    "                toadd.append(int(stagelist[i]))\n",
    "        #set the last end time to the last toadd\n",
    "        toadd.append(startTime + datetime.timedelta(minutes=len(stagelist)))\n",
    "        #add it to the df\n",
    "        df.loc[stageStartTime] = toadd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#for each line\n",
    "    #seperate out the initial timestamp\n",
    "    #get the list of sleep stages\n",
    "    #for every stage in that list\n",
    "        #increment offset\n",
    "        #see if that is a number is new\n",
    "        #if so end and write the current sleep stage\n",
    "        #start the new stage"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "print(df.head(20))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                          timestamp stage  \\\n",
      "index                                                       \n",
      "2021-01-15 03:09:00+00:00 2021-01-15 03:09:00+00:00     0   \n",
      "2021-01-15 03:21:00+00:00 2021-01-15 03:21:00+00:00     1   \n",
      "2021-01-15 03:36:00+00:00 2021-01-15 03:36:00+00:00     0   \n",
      "2021-01-15 07:30:00+00:00 2021-01-15 07:30:00+00:00     0   \n",
      "2021-01-15 08:52:00+00:00 2021-01-15 08:52:00+00:00     1   \n",
      "2021-01-15 09:01:00+00:00 2021-01-15 09:01:00+00:00     2   \n",
      "2021-01-15 09:20:00+00:00 2021-01-15 09:20:00+00:00     1   \n",
      "2021-01-15 09:35:00+00:00 2021-01-15 09:35:00+00:00     3   \n",
      "2021-01-15 09:45:00+00:00 2021-01-15 09:45:00+00:00     1   \n",
      "2021-01-15 10:30:00+00:00 2021-01-15 10:30:00+00:00     1   \n",
      "2021-01-15 11:14:00+00:00 2021-01-15 11:14:00+00:00     2   \n",
      "2021-01-15 11:28:00+00:00 2021-01-15 11:28:00+00:00     3   \n",
      "2021-01-15 12:26:00+00:00 2021-01-15 12:26:00+00:00     1   \n",
      "2021-01-15 13:30:00+00:00 2021-01-15 13:30:00+00:00     1   \n",
      "2021-01-15 13:33:00+00:00 2021-01-15 13:33:00+00:00     2   \n",
      "2021-01-15 13:47:00+00:00 2021-01-15 13:47:00+00:00     3   \n",
      "2021-01-15 14:14:00+00:00 2021-01-15 14:14:00+00:00     1   \n",
      "2021-01-15 14:57:00+00:00 2021-01-15 14:57:00+00:00     3   \n",
      "2021-01-15 15:02:00+00:00 2021-01-15 15:02:00+00:00     1   \n",
      "2021-01-15 15:16:00+00:00 2021-01-15 15:16:00+00:00     3   \n",
      "\n",
      "                                       endTimestamp  \n",
      "index                                                \n",
      "2021-01-15 03:09:00+00:00 2021-01-15 03:21:00+00:00  \n",
      "2021-01-15 03:21:00+00:00 2021-01-15 03:34:00+00:00  \n",
      "2021-01-15 03:36:00+00:00 2021-01-15 03:45:00+00:00  \n",
      "2021-01-15 07:30:00+00:00 2021-01-15 08:52:00+00:00  \n",
      "2021-01-15 08:52:00+00:00 2021-01-15 09:01:00+00:00  \n",
      "2021-01-15 09:01:00+00:00 2021-01-15 09:20:00+00:00  \n",
      "2021-01-15 09:20:00+00:00 2021-01-15 09:35:00+00:00  \n",
      "2021-01-15 09:35:00+00:00 2021-01-15 09:45:00+00:00  \n",
      "2021-01-15 09:45:00+00:00 2021-01-15 10:30:00+00:00  \n",
      "2021-01-15 10:30:00+00:00 2021-01-15 11:14:00+00:00  \n",
      "2021-01-15 11:14:00+00:00 2021-01-15 11:28:00+00:00  \n",
      "2021-01-15 11:28:00+00:00 2021-01-15 12:26:00+00:00  \n",
      "2021-01-15 12:26:00+00:00 2021-01-15 13:30:00+00:00  \n",
      "2021-01-15 13:30:00+00:00 2021-01-15 13:33:00+00:00  \n",
      "2021-01-15 13:33:00+00:00 2021-01-15 13:47:00+00:00  \n",
      "2021-01-15 13:47:00+00:00 2021-01-15 14:14:00+00:00  \n",
      "2021-01-15 14:14:00+00:00 2021-01-15 14:55:00+00:00  \n",
      "2021-01-15 14:57:00+00:00 2021-01-15 15:02:00+00:00  \n",
      "2021-01-15 15:02:00+00:00 2021-01-15 15:16:00+00:00  \n",
      "2021-01-15 15:16:00+00:00 2021-01-15 15:40:00+00:00  \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "df.to_parquet(outputFileName, compression='gzip') "
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "87e4dce2d64ddd29ba98032e602deb84283b90528a9753928e81e862a87ea896"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}